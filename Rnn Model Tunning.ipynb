{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import inspect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inspect.getfile(tf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model parameters.\n",
    "num_epochs = 1000\n",
    "total_series_lengths = 50000\n",
    "truncated_backprop_length = 15\n",
    "state_size = 4\n",
    "num_classes = 2\n",
    "echo_step = 1\n",
    "batch_size = 5\n",
    "num_batches = total_series_lengths // batch_size // truncated_backprop_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_data(total_series_lengths = 50000):\n",
    "    x = np.array(np.random.choice(2, total_series_lengths))\n",
    "#     y = np.roll(x, echo_step)\n",
    "    \n",
    "#     x = x.reshape((batch_size, -1))\n",
    "#     y = x.reshape((batch_size, -1))\n",
    "    \n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000,)\n"
     ]
    }
   ],
   "source": [
    "raw_data = generate_data()\n",
    "print(raw_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert raw data to tensors using batch producers.\n",
    "<font color=red> Note: Outdated - use TF Data API to set up pipeline.<br>\n",
    "Need to setup eager initialization for optimally utilizing the GPU, the method below lazily fetches each sample when it is required by the training step.</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_producer(raw_data, batch_size, num_steps, echo_step=1):\n",
    "    raw_data = tf.convert_to_tensor(raw_data, name='raw_data', dtype=tf.int32)\n",
    "    data_length = tf.size(raw_data)\n",
    "    batch_length = data_length // batch_size\n",
    "    data = tf.reshape(raw_data[0:batch_size * batch_length], [batch_size, batch_length])\n",
    "    \n",
    "    # epoch_size => number of steps in each spoch.\n",
    "    epoch_size = (batch_length - 1) // num_steps\n",
    "    i = tf.train.range_input_producer(epoch_size, shuffle=False).dequeue()\n",
    "    x = data[:, i * num_steps:(i+1) * num_steps]\n",
    "    x.set_shape([batch_size, num_steps])\n",
    "    y = data[:, i * (num_steps + echo_step): (i + 1) * (num_steps + echo_step)]\n",
    "    y.set_shape([batch_size, num_steps])\n",
    "    \n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Buidling the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input to the model.\n",
    "class Input:\n",
    "    def __init__(self, batch_size, num_steps, data):\n",
    "        \"\"\"\n",
    "        batch_size = number of samples in each batch.\n",
    "        num_steps = rnn time steps.\n",
    "        data = input data.\n",
    "        \"\"\"\n",
    "        self.batch_size = batch_size\n",
    "        self.num_steps = num_steps\n",
    "        self.epoch_size = ((len(data) // batch_size) - 1) // num_steps\n",
    "        self.input_data, self.targets = batch_producer(data, batch_size, num_steps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explanation for the model created below.\n",
    "> shape of the init_state => [num_layers, 2, self.batch_size, self.hidden_size]\n",
    "\n",
    "1. num_layers -> need to store initial state for every layer.\n",
    "2. 2 - state for neural network consists of two vectors -> output(h_t) and state(s_t). Dimension of two vector is equal to size of the hidden layer.\n",
    "3. in each step, samples equivalent to batch size are processed, for each state, so states for each sample need to be stored.\n",
    "4. the dimension of each output layer is equal to the dimensionality of hidden size.\n",
    "\n",
    "> unpacking along axis 0.\n",
    "\n",
    "changes (num_layers, 2, batch_size, hidden_layer_size) to num_layers * (2, batch_size, hidden_layer_size).\n",
    "\n",
    "> state_is_tuple=True\n",
    "\n",
    "required to allow the Tensorflow lstm architecture to accept state tuple as input.\n",
    "\n",
    "> output, self.state = ...dynamic_cell()\n",
    "\n",
    "output from all unrolled rnn cells with shape (batch_size, num_steps, hidden_size).<br>\n",
    "self.state is used as input for the next training sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining model functions.\n",
    "class Model:\n",
    "    def __init__(self, input_obj, is_training, hidden_size, num_layers, dropout=0.0, init_scale=0.05):\n",
    "        self.is_training = is_training\n",
    "        self.input_obj = input_obj\n",
    "        self.batch_size = input_obj.batch_size\n",
    "        self.num_steps = input_obj.num_steps\n",
    "        self.hidden_size = hidden_size\n",
    "        \n",
    "        # finally the data is loaded after the input layer into inputs.\n",
    "        inputs = input_obj.input_data\n",
    "        self.init_state = tf.placeholder(tf.float32, [num_layers, 2, self.batch_size, self.hidden_size])\n",
    "        \n",
    "        # Tensorflow LSTM models require state in format shown below.\n",
    "        state_per_layer_list = tf.unstack(self.init_state, axis=0)\n",
    "        rnn_tuple_state = tuple([tf.nn.rnn_cell.LSTMStateTuple(state_per_layer_list[layer_index][0],\n",
    "                                                          state_per_layer_list[layer_index][1])\n",
    "                                 for layer_index in range(num_layers)]\n",
    "        )\n",
    "        \n",
    "        # standard first layer LSTM cell.\n",
    "        cell = tf.contrib.rnn.LSTMCell(hidden_size, forget_bias=1.0)\n",
    "        \n",
    "        # add dropout layers if dropout layers set is required.\n",
    "        if dropout != '0.0':\n",
    "            cell = tf.nn.rnn_cell.DropoutWrapper(cell, output_keep_prob=dropout)\n",
    "            \n",
    "        # if no. of layers is more than 1, need to stack additional layers of LSTM.\\\n",
    "        # Additional layers of RNN are stacked using RNN Multicell.\n",
    "        if num_layers > 1:\n",
    "            cell_list = [cell for _ in range(num_layers)]\n",
    "            cell = tn.nn.rnn_cell.MultiRNNCell(cell_list, state_is_tuple=True)\n",
    "            \n",
    "        # using dynamic cell unroll the LSTM network.\n",
    "        output, self.state = tf.nn.dynamic_rnn(cell, inputs, dtype=tf.float32, initial_state=rnn_tuple_state)\n",
    "        \n",
    "        # flatten the rnn output to feed into a softmax layer.\n",
    "        output = tf.reshape(output, [-1, hidden_size])\n",
    "        \n",
    "        # setup the softmax layer.\n",
    "        softmax_w = tf.Variable(tf.random_uniform([hidden_size, 1], -init_scale, init_scale))\n",
    "        softmax_b = tf.Variable(tf.random_uniform([1], -init_scale, init_scale))\n",
    "        logits = tf.nn.xw_plus_b(output, softmax_w, softmax_b)\n",
    "        \n",
    "        # reshape logits for using sequence to sequence loss function.\n",
    "        logits = tf.reshape(logits, [self.batch_size, self.num_steps, 1])\n",
    "        \n",
    "        # use sequence to sequence loss.\n",
    "        loss = tf.contrib.seq2seq.sequence_loss(\n",
    "            logits,\n",
    "            self.input_obj.targets,\n",
    "            tf.ones([self.batch_sizes, self.num_steps], dtype=tf.float32),\n",
    "            average_across_timesteps=False,\n",
    "            average_across_batch=True)\n",
    "        \n",
    "        # update the cost.\n",
    "        self.cost = tf.reduce_sum(loss)\n",
    "        \n",
    "        # get the prediction cost.\n",
    "        self.softmax_out = tf.nn.softmax(tf.reshape(logits, [-1, 1]))\n",
    "        self.predict = tf.cast(tf.argmax(self.softmax_out, axis=1), tf.int32)\n",
    "        correct_prediction = tf.equal(self.predict, tf.reshape(self.input_obj.targets), [-1])\n",
    "        self.accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "        \n",
    "        if not is_training:\n",
    "            return\n",
    "        \n",
    "        self.learning_rate = tf.Variable(0.0, trainable=False)\n",
    "        \n",
    "        tvars = tf.trainable_variables()\n",
    "        # gradients are clipped, without clipping the weights get too low.\n",
    "        grads = tf.clip_by_global_norm(tf.gradients(self.cost, tvars), 5)\n",
    "        optimizer = tf.train.GradientDescentOptimizer(self.learning_rate)\n",
    "        \n",
    "        self.train_op = optimizer.apply_gradients(\n",
    "            zip(grads, tvars),\n",
    "            global_step=tf.contrib.framework.get_or_create_global_step())\n",
    "        \n",
    "        # create the updatable learning rate.\n",
    "        # new learning rate to be feed in via feed-dict argument.\n",
    "        # tf.assign is executed at the start of each epoch.\n",
    "        self.new_lr = tf.placeholder(tf.float32, shape=[])\n",
    "        self.lr_update = tf.assign(self.learning_rate, self.new_lr)\n",
    "        \n",
    "    def assign_lr(self, session, lr_value):\n",
    "        session.run(self.lr_update, feed_dict={self.new_lr: lr_value})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(train_data, num_layers, num_epochs, batch_size, model_save_name, learning_rate=1.0, \n",
    "             max_lr_epoch=10, lr_decay=0.93):\n",
    "        training_input = Input(batch_size=batch_size, num_steps=16, data=train_data)\n",
    "        m = Model(training_input, is_training=True, hidden_size=100, num_layers=num_layers)\n",
    "        init_ops = tf.global_variables_initializer()\n",
    "        \n",
    "        orig_lr = lr_decay\n",
    "        with tf.Session() as sess:\n",
    "            sess.run([init_op])\n",
    "            coord = tf.train.Coordinator()\n",
    "            threads = tf.train.start_queue_runners(coord=coord)\n",
    "            saver = tf.train.Saver()\n",
    "            \n",
    "            for epoch in range(num_epochs):\n",
    "                new_lr_rate = orig_decay ** max(epoch + 1 - max_lr_epoch, 0.0)\n",
    "                m.assign_lr(sess, learning_rate ** new_lr_decay)\n",
    "                current_state = np.zeros((num_layers, 2, batch_size, m.hidden_size))\n",
    "                for step in range(training_input.num_steps):\n",
    "                    if step % 50 != 0:\n",
    "                        cost, _, current_state = sess.run([m.cost, m.train_op, m.state], \n",
    "                                                          feed_dict={m.init_state: current_state})\n",
    "                    else:\n",
    "                        cost, _, current_state, acc = sess.run([m.cost, m.train_op, m.state, m.accuracy],\n",
    "                                                              feed_dict={m.init_state: current_state})\n",
    "                        print('Epoch {} Step {}, cost: {:.3f}, accuracy: {:.3f} '.format(epoch, step, cost, acc))\n",
    "                saver.save(sess, data_path + '\\\\' + model_save_name, global_step=epoch)\n",
    "            # last save.\n",
    "            saver.save(sess, data_path + '\\\\' + model_save_name + '-final')\n",
    "            # close the threads.\n",
    "            coord.request_stop()\n",
    "            coord.join(threads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Shape (16, 5) must have rank at least 3",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-32-13eaa6b38b08>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# train the model.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mraw_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_layers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_save_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'test_model'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-31-34f53f307b17>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(train_data, num_layers, num_epochs, batch_size, model_save_name, learning_rate, max_lr_epoch, lr_decay)\u001b[0m\n\u001b[1;32m      2\u001b[0m              max_lr_epoch=10, lr_decay=0.93):\n\u001b[1;32m      3\u001b[0m         \u001b[0mtraining_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mInput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m         \u001b[0mm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_training\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_layers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_layers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m         \u001b[0minit_ops\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mglobal_variables_initializer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-30-70bcf47e755f>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, input_obj, is_training, hidden_size, num_layers, dropout, init_scale)\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0;31m# using dynamic cell unroll the LSTM network.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m         \u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdynamic_rnn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcell\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minitial_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrnn_tuple_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m         \u001b[0;31m# flatten the rnn output to feed into a softmax layer.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow-env/lib/python3.6/site-packages/tensorflow/python/ops/rnn.py\u001b[0m in \u001b[0;36mdynamic_rnn\u001b[0;34m(cell, inputs, sequence_length, initial_state, dtype, parallel_iterations, swap_memory, time_major, scope)\u001b[0m\n\u001b[1;32m    616\u001b[0m         \u001b[0mswap_memory\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mswap_memory\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    617\u001b[0m         \u001b[0msequence_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msequence_length\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 618\u001b[0;31m         dtype=dtype)\n\u001b[0m\u001b[1;32m    619\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    620\u001b[0m     \u001b[0;31m# Outputs of _dynamic_rnn_loop are always shaped [time, batch, depth].\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow-env/lib/python3.6/site-packages/tensorflow/python/ops/rnn.py\u001b[0m in \u001b[0;36m_dynamic_rnn_loop\u001b[0;34m(cell, inputs, initial_state, parallel_iterations, swap_memory, sequence_length, dtype)\u001b[0m\n\u001b[1;32m    679\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    680\u001b[0m   inputs_got_shape = tuple(input_.get_shape().with_rank_at_least(3)\n\u001b[0;32m--> 681\u001b[0;31m                            for input_ in flat_input)\n\u001b[0m\u001b[1;32m    682\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    683\u001b[0m   \u001b[0mconst_time_steps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconst_batch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minputs_got_shape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow-env/lib/python3.6/site-packages/tensorflow/python/ops/rnn.py\u001b[0m in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    679\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    680\u001b[0m   inputs_got_shape = tuple(input_.get_shape().with_rank_at_least(3)\n\u001b[0;32m--> 681\u001b[0;31m                            for input_ in flat_input)\n\u001b[0m\u001b[1;32m    682\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    683\u001b[0m   \u001b[0mconst_time_steps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconst_batch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minputs_got_shape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tensorflow-env/lib/python3.6/site-packages/tensorflow/python/framework/tensor_shape.py\u001b[0m in \u001b[0;36mwith_rank_at_least\u001b[0;34m(self, rank)\u001b[0m\n\u001b[1;32m    762\u001b[0m     \"\"\"\n\u001b[1;32m    763\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndims\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndims\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mrank\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 764\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Shape %s must have rank at least %d\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrank\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    765\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    766\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Shape (16, 5) must have rank at least 3"
     ]
    }
   ],
   "source": [
    "# train the model.\n",
    "train(train_data=raw_data, num_layers=1, num_epochs=1, batch_size=5, model_save_name='test_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
