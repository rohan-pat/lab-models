{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## what I need to read from the dataset.\n",
    "(1950, 512) ->\n",
    "each 512 line is an input\n",
    "convert each 512 line into [0,...num_sequences], [i+1, ... num_sequences] => total no. of sequences should be equal to 512. - Task 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "freq = [i for i in range(512)]\n",
    "freq = np.array(freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# freq = np.random.sample((512, 1))\n",
    "# labels = np.random.randint(0, 4, (512, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "freq = freq.reshape(freq.shape[0], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 1\n",
    "num_steps = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(512, 16)\n"
     ]
    }
   ],
   "source": [
    "frequencies = np.zeros((512, 16), dtype=np.float32)\n",
    "print(frequencies.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16,)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frequencies[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = np.random.randint(0, 4, (512, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(512, 1)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert into num step sized repeated samples.\n",
    "def processFrequencies(freq, num_steps):\n",
    "    for i in range(freq.shape[0]):\n",
    "        if freq[i:i+num_steps, 0].shape[0] == num_steps:\n",
    "            frequencies[i, :] = freq[i:i+num_steps, 0]\n",
    "        else:\n",
    "#             print(freq[i:i+num_steps, 0].shape[0])\n",
    "            frequencies[i, :] = np.pad(freq[i:i+num_steps, 0], (0, 16-freq[i:i+num_steps, 0].shape[0]), 'edge')\n",
    "    print('loading complete')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading complete\n"
     ]
    }
   ],
   "source": [
    "freq = processFrequencies(freq, 16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(512, 16)\n"
     ]
    }
   ],
   "source": [
    "print(frequencies.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.,  1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10., 11., 12.,\n",
       "       13., 14., 15.], dtype=float32)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frequencies[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10., 11., 12., 13.,\n",
       "       14., 15., 16.], dtype=float32)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frequencies[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([511., 511., 511., 511., 511., 511., 511., 511., 511., 511., 511.,\n",
       "       511., 511., 511., 511., 511.], dtype=float32)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frequencies[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16,)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frequencies[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(512, 16)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frequencies.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "frequencies = np.reshape(frequencies, (frequencies.shape[0], frequencies.shape[1], 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process labels array from (512, 1) to (512, 4).\n",
    "Required for utilizing softmax layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_reshaped = np.zeros((512, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(labels.shape[0]):\n",
    "    labels_reshaped[i, labels[i, 0]] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_old = labels\n",
    "labels = labels_reshaped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(512, 4)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 1., 0., 0.])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 1., 0., 0.])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels[5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use the alternate method described in tensorflow - importing data tutorial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Input:\n",
    "    def __init__(self, frequencies, labels):\n",
    "        self.freq_placeholder = tf.placeholder(frequencies.dtype, frequencies.shape)\n",
    "        self.labels_placeholder = tf.placeholder(labels.dtype, labels.shape)\n",
    "        \n",
    "        self.dataset = tf.data.Dataset.from_tensor_slices((self.freq_placeholder, self.labels_placeholder))\n",
    "        self.dataset = self.dataset.batch(batch_size)\n",
    "        self.dataset = self.dataset.prefetch(16)\n",
    "        \n",
    "        self.iterator = self.dataset.make_initializable_iterator()\n",
    "        self.inputs, self.output_labels = self.iterator.get_next()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## model parameters constants.\n",
    "<font color='red'>Change parameters here for model tuning.</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_layer_dimension = 32\n",
    "number_layers = 2\n",
    "use_dropout = False\n",
    "dropout = 0.0\n",
    "num_layers = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model:\n",
    "    def __init__(self, inputs, output_labels):\n",
    "        self.init_state = tf.placeholder(tf.float32, [number_layers, 2, batch_size, hidden_layer_dimension])\n",
    "        state_per_layer_list = tf.unstack(self.init_state, axis=0)\n",
    "        rnn_state_tuples = tuple([tf.nn.rnn_cell.LSTMStateTuple(state[0], state[1]) for state in state_per_layer_list])\n",
    "\n",
    "        if use_dropout:\n",
    "            cell = tf.nn.rnn_cell.DropoutWrapper(cell, output_keep_prob=dropout)\n",
    "            \n",
    "        self.state = current_state = np.zeros((num_layers, 2, batch_size, hidden_layer_dimension))\n",
    "\n",
    "        if num_layers > 1:\n",
    "            cell_list = [self.createLSTMCells() for _ in range(num_layers)]\n",
    "            cell = tf.nn.rnn_cell.MultiRNNCell(cell_list, state_is_tuple=True)\n",
    "        elif num_layers == 1:\n",
    "            cell = createLSTMCells()\n",
    "\n",
    "        self.output, self.state = tf.nn.dynamic_rnn(cell, \n",
    "                                          inputs,\n",
    "                                          dtype=tf.float32, \n",
    "                                          initial_state=rnn_state_tuples)\n",
    "        \n",
    "        # extract the last output for time=num_seq from the output.\n",
    "        self.output = tf.transpose(self.output, [1, 0, 2])\n",
    "        self.output = tf.gather(self.output, int(self.output.shape[0]-1))\n",
    "        \n",
    "        self.logits = tf.layers.dense(inputs=self.output, units=4)\n",
    "        self.prediction = tf.nn.softmax(self.logits)\n",
    "        self.loss = tf.losses.softmax_cross_entropy(self.logits, output_labels)\n",
    "        \n",
    "        # calculate accuracy every 10 epochs.\n",
    "        self.acc, self.accuracy_ops = tf.metrics.accuracy(labels=tf.argmax(output_labels, 1),\n",
    "                                            predictions=tf.argmax(self.logits, 1)\n",
    "                                           )\n",
    "        \n",
    "    def createLSTMCells(self):\n",
    "        cell = tf.contrib.rnn.LSTMCell(hidden_layer_dimension, forget_bias=1.0)\n",
    "        return cell\n",
    "# # flatten the rnn output to feed into a softmax layer.\n",
    "# output = tf.reshape(output, [-1, hidden_size])\n",
    "\n",
    "# # setup the softmax layer.\n",
    "# softmax_w = tf.Variable(tf.random_uniform([hidden_size, 1], -init_scale, init_scale))\n",
    "# softmax_b = tf.Variable(tf.random_uniform([1], -init_scale, init_scale))\n",
    "# logits = tf.nn.xw_plus_b(output, softmax_w, softmax_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "(2, 2, 1, 32)\n"
     ]
    }
   ],
   "source": [
    "print(batch_size)\n",
    "current_state = np.zeros((num_layers, 2, batch_size, hidden_layer_dimension))\n",
    "print(current_state.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.27211427470319904\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    i = Input(frequencies, labels)\n",
    "    m = Model(i.inputs, i.output_labels)\n",
    "    sess.run(tf.local_variables_initializer())\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    for epoch in range(1):\n",
    "        sess.run(i.iterator.initializer, feed_dict={i.freq_placeholder: frequencies, i.labels_placeholder: labels})\n",
    "        accuracy_list = list()\n",
    "        for i in range(512):\n",
    "            op1, softmax_op, _, accuracy = sess.run([m.loss, m.prediction, m.state, m.accuracy_ops], \n",
    "                                                    feed_dict={m.init_state: current_state})\n",
    "            accuracy_list.append(accuracy)\n",
    "        print(sum(accuracy_list) / len(accuracy_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
